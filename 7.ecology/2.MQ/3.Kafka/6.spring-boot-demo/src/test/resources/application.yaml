spring:
  # Kafka 配置项，对应 KafkaProperties 配置类
  kafka:
    # 指定 Kafka Broker 地址，可以设置多个，以逗号分隔
    bootstrap-servers: 192.168.39.39:9092,192.168.39.40:9092,192.168.39.41:9092
    # Kafka Producer 配置项
    producer:
      # 0-不应答。1-leader 应答。all-所有 leader 和 follower 应答。
      acks: all
      # 发送失败时，重试发送的次数
      retries: 0
      # 消息的 key 的序列化
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      # 消息的 value 的序列化
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer
      # 【批量发送消息设置的三个参数：消息数量、消息的内存、超时时间。满足其一就会执行批量发送消息】
      # 每次批量发送消息数量
      batch-size: 1
      # 批量发送消息的最大内存
      buffer-memory: 1024000
      properties:
        # 超过这个时间就发送消息
        linger:
          ms: 0
    # Kafka Consumer 配置项
    consumer:
      # 设置消费者分组最初的消费进度为 earliest 。可参考博客 https://blog.csdn.net/lishuangzhe7047/article/details/74530417 理解
      auto-offset-reset: earliest
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.springframework.kafka.support.serializer.JsonDeserializer
      properties:
        spring:
          json:
            trusted:
              packages: com.mq.kafka.springbootdemo.Dto
    # Kafka Consumer Listener 监听器配置
    listener:
      # 消费监听接口监听的主题不存在时，默认会报错。所以通过设置为 false ，解决报错
      missing-topics-fatal: false

logging:
  level:
    org:
      springframework:
        # spring-kafka INFO 日志太多了，所以我们限制只打印 ERROR 级别
        kafka: ERROR
      apache:
        # kafka INFO 日志太多了，所以我们限制只打印 ERROR 级别
        kafka: ERROR

